
# MCD-Net: Towards Real-World RGB-D Video Inpainting 


Our contribution can be summarized as a *new* model and a *new* dataset.


**1. MCD-Net: using color and depth to mutually and implicitly inpaint each other**
![model](./figs/model.png)<br>
We integrate our proposed Depth Completion Network (*i.e.*, the JSCA and SRTA), Depth-Activated Transformer and Fusion Network into one framework for joint color and depth inpainting in RGB-D videos to achieve *SOTA accuracy and runtime*.

**2. VID Dataset: real RGB-D videos with dense annotated masks**
![dataset](./figs/dataset.png)<br>
We propose the first RGB-D video inpainting dataset (VID) with *authentic* RGB-D data and *elaborately-made masks* to support RGB-D video inpainting. We upload a part of videos and masks in our VID dataset at <a href="https://pan.baidu.com/s/1q9ys6ITxQgtfgYltQbdyvA?pwd=lor3" title="baidu" target="_blank">Baidu</a>.
![masks](./figs/concat-masks.jpg)<br>
We *manually refine* the object masks automatically generated by TrackAnything. The row 1 and 3 are raw masks. Raw 2 and 4 are our maually-corrected masks to ensure visually-pleasing object removal.


## A video example of in-the-wild RGB-D video inpainting
![teaser](./demo/demo.gif#pic_left)

We feed an in-the-wild video (captured in SUSTech) to our model, and the model can be well-generalized to that, making flawless inpainted results.

## More video examples
We deliver several real-world video examples inpainted by our MCD-Net here. (due to the size of video file, we only present its first frame, *please download the videos in ./demo/ for details*). <br>

![teaser](./figs/bicycle1.png)

![teaser](./figs/kid3.png)

![teaser](./figs/man1.png)

![teaser](./figs/girl1.png)
